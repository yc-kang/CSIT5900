{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65cb8ca2-8c73-468b-9678-37c62203535a",
   "metadata": {},
   "source": [
    "### Performance Autograder\n",
    "\n",
    "Evaluate the performance of the model's result\n",
    "\n",
    "Metrics:\n",
    "- Accuracy\n",
    "- Precision and Recall\n",
    "- F1 Score\n",
    "\n",
    "Input:\n",
    "- excel file of Ground Truth\n",
    "- excel file of Model's Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732ee307-853e-4033-9636-c933cefd060c",
   "metadata": {},
   "source": [
    "### Accuracy calculation approach:\n",
    "For each timeslot:\n",
    "- Calculate the intersection of unavailable students between ground truth and test results to get correctly matched students.\n",
    "- Calculate extra students in the test results (those not in the ground truth).\n",
    "- Calculate missing students from the ground truth (those not in the test results).\n",
    "\n",
    "Finally, calculate accuracy by defining a ratio that takes into account both correct, extra, and missing students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7759c3c6-0e99-4ce9-8ea3-26c12c226618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  Unnamed: 0 Monday Tuesday Wednesday Thursday Friday Saturday Sunday\n",
       " 0    8AM-9AM      C       C         C        C      C       EJ      E\n",
       " 1   9AM-10AM    BCH      CH        CH       CH     CH       EJ      E\n",
       " 2  10AM-11AM    BDH       H         H        H     DH       EJ      E\n",
       " 3  11AM-12PM      D     NaN       NaN      NaN      D       EJ      E\n",
       " 4   12PM-1PM    NaN     NaN       NaN      NaN    NaN       EJ      E,\n",
       "    Time Slot Monday Tuesday Wednesday Thursday Friday  Saturday  Sunday\n",
       " 0    8AM-9AM      C      CH        CH       CH    CDH       NaN     NaN\n",
       " 1   9AM-10AM    BCH      CH        CH       CH    CDH       NaN     NaN\n",
       " 2  10AM-11AM   BCDH      CH        CH       CH    CDH       NaN     NaN\n",
       " 3  11AM-12PM   BCDH      CH        CH       CH    CDH       NaN     NaN\n",
       " 4   12PM-1PM    NaN     NaN       NaN      NaN    NaN       NaN     NaN)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ground_truth_file = 'ground_truth_updated.xlsx'\n",
    "test_result_file = 'Gemini 1.5 Pro.xlsx'\n",
    "\n",
    "ground_truth_df = pd.read_excel(ground_truth_file)\n",
    "test_result_df = pd.read_excel(test_result_file)\n",
    "\n",
    "# print dataframes\n",
    "ground_truth_df.head(), test_result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3bbb84-b5b2-464f-8910-9bd470d9fcf1",
   "metadata": {},
   "source": [
    "### Precision and Recall, F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e61e943-1f0a-4fbb-9dd6-2b537d9afb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined Accuracy: 30.00%\n",
      "Precision: 0.47\n",
      "Recall: 0.45\n",
      "F1 Score: 0.46\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate refined accuracy, precision, recall, and F1-score\n",
    "def refined_accuracy_and_f1(ground_truth_df, test_result_df):\n",
    "    # Drop the first column (timeslot labels) for comparison\n",
    "    ground_truth_data = ground_truth_df.iloc[:, 1:]\n",
    "    test_result_data = test_result_df.iloc[:, 1:]\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_tested = 0\n",
    "    total_ground_truth = 0\n",
    "    \n",
    "    # Iterate over each cell to compare ground truth and test results\n",
    "    for col in ground_truth_data.columns:\n",
    "        for row in ground_truth_data.index:\n",
    "            # Get ground truth and test result strings, treating NaNs as empty strings\n",
    "            ground_truth_value = ground_truth_data.at[row, col] if pd.notna(ground_truth_data.at[row, col]) else \"\"\n",
    "            test_result_value = test_result_data.at[row, col] if pd.notna(test_result_data.at[row, col]) else \"\"\n",
    "            \n",
    "            # Convert both strings to sets of characters for comparison\n",
    "            ground_truth_set = set(ground_truth_value)\n",
    "            test_result_set = set(test_result_value)\n",
    "            \n",
    "            # Calculate correct, extra, and missing students\n",
    "            correct_students = ground_truth_set.intersection(test_result_set)\n",
    "            total_correct += len(correct_students)\n",
    "            total_ground_truth += len(ground_truth_set)\n",
    "            total_tested += len(test_result_set)\n",
    "    \n",
    "    # Calculate refined accuracy\n",
    "    accuracy = (total_correct / (total_ground_truth + total_tested - total_correct)) * 100 if (total_ground_truth + total_tested - total_correct) > 0 else 0\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = total_correct / total_tested if total_tested > 0 else 0\n",
    "    recall = total_correct / total_ground_truth if total_ground_truth > 0 else 0\n",
    "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Refined Accuracy: {:.2f}%\".format(accuracy))\n",
    "    print(\"Precision: {:.2f}\".format(precision))\n",
    "    print(\"Recall: {:.2f}\".format(recall))\n",
    "    print(\"F1 Score: {:.2f}\".format(f1_score))\n",
    "\n",
    "    return accuracy, precision, recall, f1_score\n",
    "\n",
    "# Calculate and display the refined accuracy, precision, recall, and F1-score\n",
    "accuracy_score, precision, recall, f1_score = refined_accuracy_and_f1(ground_truth_df, test_result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab73e28c-b88d-4b9b-bc59-2bbe531fa26f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
